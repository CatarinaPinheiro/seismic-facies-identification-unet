{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba21825",
   "metadata": {},
   "source": [
    "# Baseline solution for seismic facies identification challenge\n",
    "\n",
    "### Architecture: U-Net\n",
    "### Language: Tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb91bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "\n",
    "from keras.layers import Input, BatchNormalization, Dropout, Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "\n",
    "import jaccard_loss as jc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ee75c",
   "metadata": {},
   "source": [
    "### Define Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de347b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines convolutional block\n",
    "\n",
    "def conv2d_block(input_tensor,n_filters, kernel_size=3, batchnorm=True):\n",
    "    x = Conv2D(n_filters, (kernel_size,kernel_size),padding='same',\\\n",
    "               kernel_initializer='he_normal')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(n_filters, (kernel_size, kernel_size), padding='same',\\\n",
    "               kernel_initializer='he_normal')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# defines unet architecture\n",
    "\n",
    "def unet(img_input, out_channel, n_filters=64, dropout=0.1, k_size=3, batchnorm = True):\n",
    "    c1 = conv2d_block(img_input, n_filters*1, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters*2, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters*4, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters*8, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters*16, batchnorm=batchnorm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    u6 = Conv2DTranspose(n_filters*8, (k_size,k_size), strides = (2,2), padding='same')(c5)\n",
    "    u6 = concatenate([u6,c4])\n",
    "    c6 = conv2d_block(u6, n_filters*8, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters*4, (k_size,k_size),strides = (2,2), padding='same')(c6)\n",
    "    u7 = concatenate([u7,c3])\n",
    "    c7 = conv2d_block(u7, n_filters*4, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters*2, (k_size,k_size), strides = (2,2), padding='same')(c7)\n",
    "    u8 = concatenate([u8,c2])\n",
    "    c8 = conv2d_block(u8, n_filters*2, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters*1, (k_size,k_size), strides = (2,2), padding='same')(c8)\n",
    "    u9 = concatenate([u9,c1])\n",
    "    c9 = conv2d_block(u9, n_filters*1, kernel_size=k_size, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(out_channel, (1,1), activation='softmax')(c9)\n",
    "    model = Model(inputs= [img_input], outputs= [outputs], name ='U-Net')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d9870",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a2a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('./dataset/data_train.npz')['data']\n",
    "label_train = np.load('./dataset/labels_train.npz')['labels']\n",
    "\n",
    "\n",
    "data_patch = np.concatenate((data_train[:,:,:295], data_train[:,:,295:]))\n",
    "label_patch = np.concatenate((label_train[:,:,:295], label_train[:,:,295:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d077ad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006, 782, 590)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1353971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2012/2012 [00:11<00:00, 182.15it/s]\n"
     ]
    }
   ],
   "source": [
    "training_image_data = []\n",
    "training_label_data = []\n",
    "\n",
    "for i in tqdm (range(0, 2012)):\n",
    "    image = data_patch[i,:,:]\n",
    "    label = label_patch[i,:,:]\n",
    "    \n",
    "    image = np.expand_dims(image,axis=2).astype('float32')\n",
    "    label = np.expand_dims(label,axis=2).astype('float32')\n",
    "    \n",
    "    image = cv2.resize(image, (256,256))\n",
    "    label = cv2.resize(label,(256,256))\n",
    "    \n",
    "    training_image_data.append(image)\n",
    "    training_label_data.append(label)\n",
    "    \n",
    "    \n",
    "# convert data to array\n",
    "training_image_data = np.asarray(training_image_data)\n",
    "training_label_data = np.asarray(training_label_data)\n",
    "training_label_data = np.array(training_label_data, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870d3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, x_set, y_set):\n",
    "        self.x, self.y = x_set, y_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_x = self.x[index]\n",
    "        batch_y = self.y[index]\n",
    "        #print(np.expand_dims(batch_x,axis=0), batch_y)\n",
    "        return np.expand_dims(batch_x,axis=0), batch_y\n",
    "    \n",
    "train_dataset = DataGenerator(x_set=training_image_data,y_set=training_label_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233e4051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        ...,\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4]],\n",
       "\n",
       "       [[4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        ...,\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4]],\n",
       "\n",
       "       [[4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        ...,\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4],\n",
       "        [4, 4, 4, ..., 4, 4, 4]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]],\n",
       "\n",
       "       [[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a764342",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.metrics' has no attribute 'IoU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ab50c459370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#model.add_metric(iou, name=iou)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIoU\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.metrics' has no attribute 'IoU'"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "cropsize = 256\n",
    "lr = 0.0001\n",
    "n_classes = 7\n",
    "y_true = Input(shape=(cropsize,cropsize,1), name='y_true')\n",
    "model = unet(y_true, 7, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model = Model(inputs=model.inputs, outputs=model.outputs)\n",
    "\n",
    "# Optimizer\n",
    "optim = K.optimizers.Adam(lr)\n",
    "\n",
    "# Define loss \n",
    "#loss = generalized_dice_loss_w(y_true, model.get_layer(\"softmax\").output)\n",
    "#model.add_loss(loss)\n",
    "jaccard_loss = jc.dice_coef_9cat_loss(y_true, model.output)\n",
    "\n",
    "#iou = jc.iou_score(y_true, model.output, n_classes, class_weights=1.)[0]\n",
    "#print('iou',iou)\n",
    "\n",
    "#dice_loss = sm.losses.DiceLoss(class_weights=weights) \n",
    "model.add_loss(jaccard_loss)\n",
    "\n",
    "#model.add_metric(iou, name=iou)\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanIoU(num_classes=7)]\n",
    "\n",
    "model.compile(optimizer= optim, loss= None, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4eaf1813",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-9b62b94b38a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn_batches_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mn_batches_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_image' is not defined"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "acc_history = []\n",
    "miou_history = []\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "train_image = data\n",
    "n_batches_train = len(train_image)//batch_size\n",
    "n_batches_val = len(val_image)//batch_size\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch {}-{}'.format(epoch+1, num_epochs))\n",
    "    batch_start = 0 # Initial batch value of j epoch\n",
    "    batch_end = batch_size  # Initial batch end of j epoch\n",
    "    loss = 0\n",
    "    iou_train = 0\n",
    "    previous_loss = 99999 # initial previous_loss to put loss_val\n",
    "    previous_loss_val = 99999\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in range(n_batches_train):\n",
    "        history = model.train_on_batch([train_image[batch_start:batch_end],\n",
    "                                        train_label[batch_start:batch_end]],\n",
    "                                       None)\n",
    "        #print(history)\n",
    "        batch_start+=batch_size\n",
    "        batch_end+=batch_size\n",
    "        loss+=history[0]\n",
    "        iou_train += history[1]\n",
    "    end_time = time.time()\n",
    "    print(\"epoch time: \",end_time - start_time)\n",
    "    \n",
    "    loss = loss/n_batches_train # Average loss function of all batches in j epoch (train)\n",
    "    iou_train = iou_train/n_batches_train # Average IOU of all batches in j epoch (train)\n",
    "    \n",
    "    #Val\n",
    "    \n",
    "    batch_start_val = 0\n",
    "    batch_end_val = batch_size\n",
    "    loss_val = 0\n",
    "    iou_val = 0\n",
    "    \n",
    "    for i in range(n_batches_val):  \n",
    "        history_val = model.test_on_batch([val_image[batch_start_val:batch_end_val],\n",
    "                                           val_label[batch_start_val:batch_end_val]],\n",
    "                                         None)\n",
    "        batch_start_val+=batch_size\n",
    "        batch_end_val+=batch_size\n",
    "        loss_val+=history_val[0]\n",
    "        iou_val += history_val[1]\n",
    "        \n",
    "    loss_val = loss_val/n_batches_val\n",
    "    iou_val = iou_val/n_batches_val\n",
    "    \n",
    "    if loss_val < previous_loss_val:\n",
    "        model.save_weights('diceloss_unet_' + str(cropsize)+ \"_\" + backbone_net + \"_nclass_\"\n",
    "                           + str(n_classes) + '_seg_' + 'weights.h5')\n",
    "        previous_loss_val = loss_val\n",
    "        \n",
    "    if loss < previous_loss:\n",
    "        model.save_weights('diceloss_unet_' + str(cropsize) + \"_\" + backbone_net + \"_nclass_\" \n",
    "                           + str(n_classes) + '_seg_' + 'weights_best_Train.h5')\n",
    "        loss_ant = loss\n",
    "\n",
    "\n",
    "    print(\"loss train: \",loss)\n",
    "    print(\"iou train: \",iou_train)\n",
    "    print(\"loss val: \",loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c77452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(x_size, name='img')\n",
    "model = unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ea2521e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2012, 256, 256)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "750cc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d5406d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f3024b34090>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
